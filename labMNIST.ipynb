{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The batch size is the number of samples considered at each optimisation iteration\n",
    "batch_size = 128\n",
    "# There are 10 possible digits\n",
    "num_classes = 10\n",
    "# Epochs is the number of times the training set is used\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "60000 train samples\n",
      "10000 train samples\n"
     ]
    }
   ],
   "source": [
    "# split and preprocess data\n",
    "\n",
    "# the data , split between train and test sets\n",
    "( x_train , y_train ) ,( x_test , y_test ) = mnist . load_data ()\n",
    "\n",
    "# Each image in the MNIST dataset has 28*28 = 74 pixels.\n",
    "# We reshape this 28 x28 matrix into a 784 array\n",
    "x_train = x_train.reshape (60000, 784)\n",
    "x_test = x_test.reshape (10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# The RGB values are between 0 and 255 , and we want to input values between 0 and 1.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print (x_train.shape[0], 'train samples')\n",
    "print (x_test.shape[0], 'train samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# e . g instead of \"8\" we want [0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,1 ,0]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We initialize an empty Sequential model\n",
    "model = Sequential ()\n",
    "\n",
    "# And then sequentially add new layers .\n",
    "# A Dense layer is the one we covered this chapter, where a neuron connects to all the neurons in the following layer .\n",
    "# For each layer, we have to specify the activation function and the output size . \n",
    "# In the first layer, we also have to specify the input shape .\n",
    "model.add(Dense(512, activation = 'relu',input_shape =(784,)))\n",
    "\n",
    "\n",
    "# Dropout is a regularization technique (to prevent overfitting )\n",
    "model.add (Dropout(0.2))\n",
    "model.add (Dense(512, activation = 'relu'))\n",
    "model.add (Dropout(0.2))\n",
    "model.add (Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "# Model summary . Informational only .\n",
    "model . summary ()\n",
    "# Once the neural network structure is set we compile it.\n",
    "# That means associate a loss function and an optimiser with it .\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = SGD(), metrics = ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 1.2860 - accuracy: 0.6589 - val_loss: 0.5356 - val_accuracy: 0.8817\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.5711 - accuracy: 0.8399 - val_loss: 0.3450 - val_accuracy: 0.9132\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.4513 - accuracy: 0.8688 - val_loss: 0.2891 - val_accuracy: 0.9203\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.3995 - accuracy: 0.8835 - val_loss: 0.2606 - val_accuracy: 0.9282\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.3657 - accuracy: 0.8938 - val_loss: 0.2402 - val_accuracy: 0.9318\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.3388 - accuracy: 0.9015 - val_loss: 0.2259 - val_accuracy: 0.9350\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.3188 - accuracy: 0.9084 - val_loss: 0.2140 - val_accuracy: 0.9397\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.3008 - accuracy: 0.9132 - val_loss: 0.2024 - val_accuracy: 0.9430\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2865 - accuracy: 0.9164 - val_loss: 0.1935 - val_accuracy: 0.9473\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2714 - accuracy: 0.9211 - val_loss: 0.1830 - val_accuracy: 0.9505\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.2610 - accuracy: 0.9244 - val_loss: 0.1751 - val_accuracy: 0.9528\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2492 - accuracy: 0.9279 - val_loss: 0.1685 - val_accuracy: 0.9550\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2394 - accuracy: 0.9309 - val_loss: 0.1618 - val_accuracy: 0.9567\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2291 - accuracy: 0.9334 - val_loss: 0.1569 - val_accuracy: 0.9588\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2211 - accuracy: 0.9369 - val_loss: 0.1503 - val_accuracy: 0.9603\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2143 - accuracy: 0.9376 - val_loss: 0.1463 - val_accuracy: 0.9613\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2066 - accuracy: 0.9392 - val_loss: 0.1419 - val_accuracy: 0.9628\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.2008 - accuracy: 0.9411 - val_loss: 0.1370 - val_accuracy: 0.9635\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1940 - accuracy: 0.9427 - val_loss: 0.1337 - val_accuracy: 0.9658\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1899 - accuracy: 0.9446 - val_loss: 0.1291 - val_accuracy: 0.9660\n"
     ]
    }
   ],
   "source": [
    "# After the network is compiled we can train it , using\n",
    "# our training set .\n",
    "history = model.fit(x_train, y_train,\n",
    "batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        verbose = 1,\n",
    "        validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.15467169880867004\n",
      "Test accuracy: 0.9541000127792358\n"
     ]
    }
   ],
   "source": [
    "# Finally , we check the performance of the model\n",
    "# in the test set\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print ('Test loss:', score[0])\n",
    "print ('Test accuracy:' , score [1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
